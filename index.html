<!DOCTYPE html>
<html>

<head>
  <meta http-equiv="refresh" content="0; URL=https://neural-bcc.github.io/"/>
  <meta charset="utf-8">
  <meta name="description" content="NeuralFieldsBeyondCams">
  <meta name="keywords" content="NeuralFieldsBeyondCams">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta property="og:image" content="./static/img/neural_fields.webp" />
  <title>Neural Fields Beyond Conventional Cameras</title>
  
  <meta property="og:description" content="Neural Fields Beyond Conventional Cameras"/>
  <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">
  <script defer src="assets/fontawesome.all.min.js"></script>

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:creator" content="@mmalex">
  <meta name="twitter:title" content="Neural Fields Beyond Conventional Cameras">
  <meta name="twitter:description" content="The first workshop on neural fields beyond conventional cameras, hosted at ECCV 2024.">

  <link rel="icon" href="./static/img/camera.png">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">
  <link rel="stylesheet" href="css/style.css"> <!-- Resource style -->
  <script src="js/modernizr.js"></script> <!-- Modernizr -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>

  <style>
    .rcorners1 {
      border-radius: 10px;
      background: #ffffffd0;
      padding: 5px;
      font-size: 120%;
      color: #5c5c5c;
    }

    .button {
      border-radius: 10px;
      background: #ffffffd0;
      padding: 5px 15px 5px 15px;
    }

    .dropdown {
      position: relative;
      display: inline-block;
    }

    .dropdown-content {
      display: none;
      position: absolute;
      /* background-color: #f9f9f9; */
      min-width: 140px;
      box-shadow: 0px 8px 16px 0px rgba(0, 0, 0, 0.2);
      padding: 5px 15px 5px 15px;
      z-index: 1;
    }

    .dropdown:hover .dropdown-content {
      display: block;
    }
  </style>
</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
              <p class="title is-1 publication-title">2<sup>nd</sup> Workshop on Neural Fields Beyond Conventional Cameras
              </p>
            </h1>
            <h1 class="is-is-5" style="color: #5c5c5c;">in conjunction with CVPR 2025, Nashville, Tennessee.</h1>
            <b>Date: TBD</b><br>
            <b>Location: TBD, Nashville, Tennessee</b><br>
            <b>Please note this webpage is out of date! Please refer to: https://neural-bcc.github.io/</b><br>
            <br>
          </div>
        </div>
      </div>
    </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h2 class="subtitle has-text-centered">
          <a href="#schedule" class="button">Schedule</a>
          <a href="#speakers" class="button">Speakers</a>
          <a href="#call4paper" class="button">Call for Papers</a>
          <a href="#relatedwork" class="button">Related Work</a>
          <!-- <a href="#challenge" class="button">Challenge</a> -->
          <a href="#organizers" class="button">Organizers</a>
          <a href="#previous" class="button">Previous Editions</a>
        </h2>
        
      </div>
    </div>
  </section>

  <!-- ############################## -->
  <!-- motivation -->
  <section class="section" style="margin-top: -50px">
    <div class="container is-max-desktop">
      <section class="section" id="Motivation">
        <div class="container is-max-desktop content">
          <h2 class="title">Motivation üí°</h2>
          <div class="content has-text-justified">
            Neural fields have been widely adopted for learning novel view synthesis and 3D reconstruction from RGB images by modelling transport of light in the visible spectrum. This workshop focuses on <em>neural fields beyond conventional cameras</em>, including (1) learning neural fields from data from different sensors across the electromagnetic spectrum and beyond, such as lidar, cryo-electron microscopy (cryoEM), thermal, event cameras, acoustic, and more, and (2) modelling associated physics-based differentiable forward models and/or the physics of more complex light transport (reflections, shadows, polarization, diffraction limits, optics, scattering in fog or water, etc.). Our goal is to bring together a diverse group of researchers using neural fields across sensor domains to foster learning and discussion in this growing area. 
          </div>
        </div>
      </section>

    <section class="section" style="margin-top: -50px">
      <div class="container is-max-desktop">
        <!-- ############################## -->
        <!-- scheduler -->
        <section class="section" id="schedule">
          <div class="container is-max-desktop content">
            <h2 class="title">Schedule ‚è∞ (Tentative)</h2>
            <div class="content has-text-justified">
              <table class="table table-striped">
                <tr>
                  <td width="130">9:00 - 9:05</td>
                  <td width="500" style="background-color:#e4ffc2">Welcome & Introduction</td>
                  <td></td>
                </tr>
                <tr>
                  <td>9:05 - 9:30</td>
                  <td style="background-color:#cae1ff">Keynote: Jingyi Yu <b></b></td>
                  <td></td>
                </tr>
                <tr>
                  <td>9:30 - 9:55</td>
                  <td style="background-color:#cae1ff">Keynote: Sara Fridovich-Keil <b></b></td>
                  <td></td>
                </tr>
                <tr>
                  <td>9:55 - 10:05</td>
                  <td style="background-color:#ffe0c6">Paper Spotlight: TBD<b></b></td>
                  <td></td>
                </tr>
                <tr>
                  <td>10:05 - 10:15</td>
                  <td style="background-color:#ffe0c6">Paper Spotlight: TBD<b></b></td>
                  <td></td>
                </tr>
                <tr>
                  <td>10:15 - 10:25</td>
                  <td style="background-color:#ffe0c6">Paper Spotlight: TBD<b></b></td>
                  <td></td>
                </tr>
                <tr>
                  <td>10:25 - 11:10</td>
                  <td style="background-color:#e4ffc2">Poster Session & Coffee Break</td>
                  <td></td>
                </tr>
                <tr>
                  <td>11:10 - 11:35</td>
                  <td style="background-color:#cae1ff">Keynote: Felix Heide</td>
                  <td></td>
                </tr>
                <tr>
                  <td>11:35 - 12:00</td>
                  <td style="background-color:#cae1ff">Keynote: Christian Richardt<b></b></td>
                  <td></td>
                </tr>
                <tr>
                  <td>12:00 - 12:25</td>
                  <td style="background-color:#cae1ff">Keynote: Katherine Skinner<b></b></td>
                  <td></td>
                </tr>                
                <tr>
                  <td>12:25 - 1:00</td>
                  <td style="background-color:#e4ffc2">Panel Discussion<br>Moderator: TBD<br>Panelists: TBD</td>
                  <td></td>
                </tr>
              </table>
            </div>
          </div>
        </section>

        <!-- ############################## -->
        <!-- invited speakers -->
        <section class="section" id="Invited Speakers">
          <div class="container is-max-desktop content">
            <h2 class="title" id="speakers">Keynote Speakers üßë‚Äçüè´</h2>

            <a href="https://davidlindell.com" target="_blank">
              <div class="card">
                <div class="card-content">
                  <div class="columns is-vcentered">
                    <div class="column is-one-quarter">
                      <figure class="image is-128x128">
                        <img class="is-rounded" src="static/img/david_lindell.jpeg">
                      </figure>
                    </div>
                    <div class="column">
                      <p class="title is-4">David Lindell</p>
                      <p class="subtitle is-6">University of Toronto</p>
                    </div>
                  </div>
                  <div class="content">
                    David Lindell is an Assistant Professor in the Department of Computer Science at the University of Toronto and founding member of the Toronto Computational Imaging Group. His work is at the intersection of machine learning, computational imaging, and computer vision. Along these lines he has worked on next-generation computational imaging systems for imaging around corners and through scattering media, and new machine learning algorithms for representing and processing signals. His work is relevant to a broad range of applications in computer graphics, vision, and remote sensing.
                  </div>
                </div>
              </div>
            </a>  
            <a href="https://cvg.cit.tum.de/members/cremers" target="_blank">
              <div class="card">
                <div class="card-content">
                  <div class="columns is-vcentered">
                    <div class="column is-one-quarter">
                      <figure class="image is-128x128">
                        <img class="is-rounded" src="static/img/daniel_cremers.png">
                      </figure>
                    </div>
                    <div class="column">
                      <p class="title is-4">Daniel Cremers</p>
                      <p class="subtitle is-6">TU Munich</p>
                    </div>
                  </div>
                  <div class="content">
                    Daniel Cremers is a Professor at Technical University of Munich where he holds the Chair of Computer Vision and Artificial Intelligence. His publications received several awards, including the 'Best Paper of the Year 2003' (Int. Pattern Recognition Society), the 'Olympus Award 2004' (now called 'German Pattern Recognition Award') and the '2005 UCLA Chancellor's Award for Postdoctoral Research'. For pioneering research he received a Starting Grant (2009), two Proof of Concept Grants (2014 \& 2018), a Consolidator Grant (2015) and an Advanced Grant (2020) by the European Research Council. In December 2010 he was listed among "Germany's top 40 researchers below 40" (Capital). On March 1st 2016, Prof. Cremers received the Gottfried Wilhelm Leibniz Award, the biggest award in German academia. In 2022 and 2023, he was listed among the top 10 most influential scholars in robotics of the last decade. He serves as co-founder, advisor and business angel to several startups.
                  </div>
                </div>
              </div>
            </a>
            <a href="https://jonbarron.info" target="_blank">
              <div class="card">
                <div class="card-content">
                  <div class="columns is-vcentered">
                    <div class="column is-one-quarter">
                      <figure class="image is-128x128">
                        <img class="is-rounded" src="static/img/jon_barron.jpeg">
                      </figure>
                    </div>
                    <div class="column">
                      <p class="title is-4">Jon Barron</p>
                      <p class="subtitle is-6">Google</p>
                    </div>
                  </div>
                  <div class="content">
                    Jon Barron is a senior staff research scientist at Google Research, where he works on computer vision and machine learning. He received a PhD in Computer Science from the University of California, Berkeley in 2013, where he was advised by Jitendra Malik, and he received a Honours BSc in Computer Science from the University of Toronto in 2007. He received a National Science Foundation Graduate Research Fellowship in 2009, the C.V. Ramamoorthy Distinguished Research Award in 2013, and the PAMI Young Researcher Award in 2020. His works have received awards at ECCV 2016, TPAMI 2016, ECCV 2020, ICCV 2021, CVPR 2022, the 2022 Communications of the ACM, and ICLR 2023.
                  </div>
                </div>
              </div>
            </a> 
            <a href="https://www.viseaon.haifa.ac.il/" target="_blank">
              <div class="card">
                <div class="card-content">
                  <div class="columns is-vcentered">
                    <div class="column is-one-quarter">
                      <figure class="image is-128x128">
                        <img class="is-rounded" src="static/img/tali_treibitz.webp">
                      </figure>
                    </div>
                    <div class="column">
                      <p class="title is-4">Tali Treibitz</p>
                      <p class="subtitle is-6">University of Haifa</p>
                    </div>
                  </div>
                  <div class="content">
                    Tali Treibitz is heading the Viseaon marine imaging lab in the School of Marine Sciences in the University of Haifa since 2014. She received her PhD degree in electrical engineering from the Technion-Israel Institute of Technology in 2010. Between 2010-2013 she was a post-doctoral researcher in the department of computer science and engineering, in the University of California, San Diego and in the Marine Physical Lab in Scripps Institution of Oceanography. Her lab focuses on cutting edge research in underwater computer vision, scene, color and 3D reconstruction, automatic analysis of scenes, and autonomous decision making based on visual input.
                  </div>
                </div>
              </div>
            </a>  
            <a href="https://www.cs.columbia.edu/~vondrick" target="_blank">
              <div class="card">
                <div class="card-content">
                  <div class="columns is-vcentered">
                    <div class="column is-one-quarter">
                      <figure class="image is-128x128">
                        <img class="is-rounded" src="static/img/carl_vondrick.jpeg">
                      </figure>
                    </div>
                    <div class="column">
                      <p class="title is-4">Carl Vondrick</p>
                      <p class="subtitle is-6">Columbia University</p>
                    </div>
                  </div>
                  <div class="content">
                    Carl Vondrick is an Associate professor of computer science at Columbia University. His research focuses on computer vision and machine learning. By training machines to observe and interact with their surroundings, his group aims to create robust and versatile models for perception. They often develop visual models that capitalize on large amounts of unlabeled data and transfer across tasks and modalities. Other interests include sound and language, interpretable models and high-level reasoning. Recent work includes 3D reconstruction from shadows and thermal reflections. 
                  </div>
                </div>
              </div>
            </a>
            
          </div>
        </section>

        <!-- call for papers -->
        <section class="section" id="Call for papers">
          <div class="container is-max-desktop content">
            <h2 class="title" id="call4paper">Call for Papers üì¢üì¢</h2>
            This workshop aims to bring together a diverse group of researchers using neural fields and gaussian splatting (GS) across sensor domains to foster learning and discussion in this growing area. We welcome paper submissions on all topics related to neural fields beyond conventional cameras. Papers on gaussian splatting are welcomed within this. Accepted papers will be posted on the workshop website, but will not be part of the ECCV proceedings. Relevant topics for this workshop include but are not limited to:
            <ul>
              <li>Neural field/GS-based reconstruction and view synthesis using non-RGB sensor measurements (LiDAR, Thermal, Event, CT, MRI, Ultrasound, Cryo-EM, Sonar, etc)</li>
              <li>Neural fields/GS for computational imaging</li>
              <li>Neural fields/GS for sensor modelling and calibration</li>
              <li>Neural fields/GS for modelling visual cues (shadows, reflections, polarization, etc)</li>
              <li>Applications of the above to autonomous vehicles, AR/VR/XR, robotics, medicine, scientific dis-
                covery, and beyond</li>
            </ul>

            <h2 class="title" id="">Style and Author Instructions</h2>
            <ul>
              <li>
                <b>Paper Length:</b> For new work (not previously accepted or published in a peer-reviewed venue), please use the official templates provided by <a href="https://github.com/cvpr-org/author-kit/releases">CVPR 2025</a> (8 pages max). If your paper has already been accepted or published in a peer-reviewed venue, you may submit it in its original format and please specify in the submission where it was previously accepted.
              </li>
              <li>
                <b>Dual Submissions:</b> The workshop is non-archival. We encourage papers accepted to CVPR 2025 to present at our workshop.
              </li>
              <li>
                <b>Presentation Forms:</b> All accepted papers will get poster presentations during the workshop; selected papers will get oral presentations.
              </li>
            </ul>
            
            <p class="text-justify">
              All submissions should be anonymized. If you plan to submit the work for publication in the future, we strongly recommend submitting a four page version to this workshop. Supplementary material is optional with supported formats: pdf, mp4 and zip.
            </p>
          <p>All submissions should adhere to the <a
                  href="https://cvpr.thecvf.com/Conferences/2025/AuthorGuidelines">CVPR 2025 submission
                  guidelines</a>, wherever applicable.
          </p>
          <p>
              <strong>Submission Portal: </strong><a href="">TBD</a>
          </p>
          <p><strong>Paper Review Timeline:</strong>
          <table class="table">
              <tr>
                  <th scope="col">Paper Submission and supplemental material deadline</th>
                  <td> TBD (AoE time)</td>
              </tr>
              <tr>
                  <th scope="col">Notification to authors</th>
                  <td> TBD (AoE time) </td>
              </tr>
              <tr>
                  <th scope="col">Camera ready deadline</th>
                  <td> TBD (AoE time) </td>
              </tr>
          </table>

          </div>
        </section>


        <section class="section" id="Related works">
          <div class="container is-max-desktop content">
            <h2 class="title" id="relatedwork">Related Works üßë‚Äçü§ù</h2>
            Below is a collection of related works in the field of neural fields beyond conventional cameras.
            Please
            feel free to get in touch to add other works as well.
            <ul>
              <li><a href="https://arxiv.org/abs/2312.14239">	
                PlatoNeRF: 3D Reconstruction in Plato's Cave via Single-View Two-Bounce Lidar</a> CVPR 2024
              </li>
              <li><a href="https://arxiv.org/abs/2312.05247">Dynamic LiDAR Re-simulation using Compositional Neural Fields</a> CVPR 2024
              </li>
              <li><a href="https://arxiv.org/abs/2305.16321">Eclipse: Disambiguating Illumination and Materials using Unintended Shadows</a> CVPR 2024 </li>
              <li><a href="https://arxiv.org/abs/2208.11300">E-NeRF: Neural Radiance Fields from a Moving Event Camera</a> RA-L 2023 </li>
              <li><a href="https://arxiv.org/abs/2301.10520">Ultra-NeRF: Neural Radiance Fields for Ultrasound Imaging</a> MIDL 2023 </li>
              <li><a href="https://arxiv.org/abs/2307.09555">Transient Neural Radiance Fields for Lidar View Synthesis and 3D Reconstruction</a> NeurIPS 2023 </li>
              <li><a href="https://arxiv.org/abs/2305.01643">	
                Neural LiDAR Fields for Novel View Synthesis</a> ICCV 2023
              </li>
              <li><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Shandilya_Neural_Fields_for_Structured_Lighting_ICCV_2023_paper.pdf">Neural Fields for Structured Lighting</a> ICCV 2023 </li>
              <li><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Qi_E2NeRF_Event_Enhanced_Neural_Radiance_Fields_from_Blurry_Images_ICCV_2023_paper.pdf">	
                E<sup>2</sup>NeRF: Event Enhanced Neural Radiance Fields from Blurry Images</a> ICCV 2023
              </li>
              <li><a href="https://arxiv.org/abs/2212.04531">ORCa: Glossy Objects as Radiance Field Cameras</a> CVPR 2023 </li>
              <li><a href="https://arxiv.org/abs/2305.01652">Humans as Light Bulbs: 3D Human Reconstruction from Thermal Reflection</a> CVPR 2023 </li>
              <li><a href="https://arxiv.org/abs/2304.07743">SeaThru-NeRF: Neural Radiance Fields in Scattering Media</a> CVPR 2023 </li>
              <li><a href="https://arxiv.org/abs/2206.11896">EventNeRF: Neural Radiance Fields from a Single Colour Event Camera</a> CVPR 2023 </li>
              <li><a href="https://ojs.aaai.org/index.php/AAAI/article/view/20171">Neural Interferometry: Image Reconstruction from Astronomical Interferometers Using Transformer-Conditioned Neural Fields</a> AAAI 2022 </li>
              <li><a href="https://arxiv.org/abs/2204.00628">Learning Neural Acoustic Fields</a> NeurIPS 2022 </li>
              <li><a href="https://arxiv.org/abs/2203.13458">	
                PANDORA: Polarization-Aided Neural Decomposition Of Radiance</a> ECCV 2022
              </li>                
              <li><a href="https://arxiv.org/abs/2202.01020">Medical Neural Radiance Fields for Reconstructing 3D-aware CT-Projections from a Single X-ray</a> EMBC 2022
              </li>
              <li><a href="https://arxiv.org/abs/2109.15271">T√∂RF: Time-of-Flight Radiance Fields for Dynamic Scene View Synthesis</a> NeurIPS 2021 </li>
              <li><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhong_CryoDRGN2_Ab_Initio_Neural_Reconstruction_of_3D_Protein_Structures_From_ICCV_2021_paper.pdf">CryoDRGN2: Ab initio neural reconstruction of 3D protein structures from real cryo-EM images</a> ICCV 2021 </li>
              <br>
            </ul>
            and many more ...


            </ul>
          </div>
        </section>
          
          

        <!-- ############################## -->
        <!-- organizers -->
        <section class="section" id="Organizers">
          <div class="container is-max-desktop content">
            <h2 class="title" id="organizers">Organizers</h2>
            
            <div class="columns is-centered is-variable is-0">

              <div class="column is-one-quarter">
                <a href="https://tzofi.github.io">
                  <div class="card">
                    <div class="card-image">
                      <figure class="image">
                        <img class="is-rounded" src="./static/img/Tzofi.jpg" alt="Image of Tzofi Klinghoffer">
                      </figure>
                    </div>
                    <div class="card-content">
                      <div class="media">
                        <div class="media-content" style="overflow-x: unset;">
                          <p class="title is-7 is-spaced">Tzofi Klinghoffer</p>
                          <p class="subtitle is-7">MIT Media Lab </p>
                        </div>
                      </div>
                    </div>
                  </div>
                </a>
              </div>
              <div class="column is-one-quarter">
                <a href="https://shengyuh.github.io">
                  <div class="card">
                    <div class="card-image">
                      <figure class="image">
                        <img class="is-rounded" src="./static/img/Shengyu.jpeg" alt="Image of Shengyu Huang">
                      </figure>
                    </div>
                    <div class="card-content">
                      <div class="media">
                        <div class="media-content" style="overflow-x: unset;">
                          <p class="title is-7 is-spaced">Shengyu Huang</p>
                          <p class="subtitle is-7">ETH Z√ºrich</p>
                        </div>
                      </div>
                    </div>
                  </div>
                </a>
              </div>
              <div class="column is-one-quarter">
                <a href="">
                  <div class="card">
                    <div class="card-image">
                      <figure class="image">
                        <img class="is-rounded" src="./static/img/Daniel.jpg" alt="Placeholder image">
                      </figure>
                    </div>
                    <div class="card-content">
                      <div class="media">
                        <div class="media-content" style="overflow-x: unset;">
                          <p class="title is-7 is-spaced">Daniel Gilo</p>
                          <p class="subtitle is-7">Technion</p>
                        </div>
                      </div>
                    </div>
                  </div>
                </a>
              </div>
              <div class="column is-one-quarter">
                <a href="https://www.media.mit.edu/people/ktiwary/overview/">
                  <div class="card">
                    <div class="card-image">
                      <figure class="image">
                        <img class="is-rounded" src="./static/img/Kushagra.png" alt="Image of Kushagra Tiwary">
                      </figure>
                    </div>
                    <div class="card-content">
                      <div class="media">
                        <div class="media-content" style="overflow-x: unset;">
                          <p class="title is-7 is-spaced">Kushagra Tiwary</p>
                          <p class="subtitle is-7">MIT Media Lab</p>
                        </div>
                      </div>
                    </div>
                  </div>
                </a>
              </div>
              

            </div>

            <div class="columns is-centered is-variable is-0">

              <div class="column is-one-fifth">
                <a href="https://akshatdave.github.io">
                  <div class="card">
                    <div class="card-image">
                      <figure class="image">
                        <img class="is-rounded" src="./static/img/Akshat.jpg" alt="Image of Akshat Dave">
                      </figure>
                    </div>
                    <div class="card-content">
                      <div class="media">
                        <div class="media-content" style="overflow-x: unset;">
                          <p class="title is-7 is-spaced">Akshat Dave</p>
                          <p class="subtitle is-7">MIT Media Lab</p>
                        </div>
                      </div>
                    </div>
                  </div>
                </a>
              </div>
              <div class="column is-one-fifth">
                <a href="https://lingjie0206.github.io">
                  <div class="card">
                    <div class="card-image">
                      <figure class="image">
                        <img class="is-rounded" src="./static/img/Lingjie.jpg" alt="Image of Lingjie Liu">
                      </figure>
                    </div>
                    <div class="card-content">
                      <div class="media">
                        <div class="media-content" style="overflow-x: unset;">
                          <p class="title is-7 is-spaced">Lingjie Liu</p>
                          <p class="subtitle is-7">Univ. of Pennsylvania</p>
                        </div>
                      </div>
                    </div>
                  </div>
                </a>
              </div>
              <div class="column is-one-fifth">
                <a href="https://jamestompkin.com">
                  <div class="card">
                    <div class="card-image">
                      <figure class="image">
                        <img class="is-rounded" src="./static/img/James.jpg" alt="Image of James Tompkin">
                      </figure>
                    </div>
                    <div class="card-content">
                      <div class="media">
                        <div class="media-content" style="overflow-x: unset;">
                          <p class="title is-7 is-spaced">James Tompkin</p>
                          <p class="subtitle is-7">Brown University</p>
                        </div>
                      </div>
                    </div>
                  </div>
                </a>
              </div>
              <div class="column is-one-fifth">
                <a href="https://orlitany.github.io">
                  <div class="card">
                    <div class="card-image">
                      <figure class="image">
                        <img class="is-rounded" src="./static/img/orlitany_square.jpg" alt="Image of Or Litany">
                      </figure>
                    </div>
                    <div class="card-content">
                      <div class="media">
                        <div class="media-content" style="overflow-x: unset;">
                          <p class="title is-7 is-spaced">Or Litany</p>
                          <p class="subtitle is-7">NVIDIA, Technion</p>
                        </div>
                      </div>
                    </div>
                  </div>
                </a>
              </div>
              <div class="column is-one-fifth">
                <a href="https://www.media.mit.edu/people/raskar/overview/">
                  <div class="card">
                    <div class="card-image">
                      <figure class="image">
                        <img class="is-rounded" src="./static/img/Ramesh.jpg" alt="Image of Ramesh Raskar">
                      </figure>
                    </div>
                    <div class="card-content">
                      <div class="media">
                        <div class="media-content" style="overflow-x: unset;">
                          <p class="title is-7 is-spaced">Ramesh Raskar</p>
                          <p class="subtitle is-7">MIT Media Lab</p>
                        </div>
                      </div>
                    </div>
                  </div>
                </a>
              </div>
              

            </div>

          </div>
        </section>

          <!-- <section class="section" id="Sponsors">
        <div class="container is-max-desktop content">
          <h2 class="title">Sponsors </h2>
        </div>
      </section> -->

        <section class="section" id="Previous Editions">
          <div class="container is-max-desktop content">
            <h2 class="title" id="previous">Previous Workshop Editions</h2>
            <li>
              <a href="2024/2024.html">2024 - 1st Edition @ European Conference on Computer Vision</a><br>
            </li>
          </div>
        </section>

          <footer class="footer">
            <div class="container">
              <div class="content">
                <p>
                  This website is licensed under a <a rel="license"
                    href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                    Commons Attribution-ShareAlike 4.0 International License</a>.
                  <br />
                  It borrows the source code of <a href="https://github.com/nerfies/nerfies.github.io">this website</a>.
                  We would like to thank Utkarsh Sinha and Keunhong Park.
                  <br>
                </p>
              </div>
            </div>
          </footer>
</body>
<script src="js/jquery-2.1.1.js"></script>
<script src="js/jquery.mobile.custom.min.js"></script> <!-- Resource jQuery -->
<script src="js/main.js"></script> <!-- Resource jQuery -->

</html>
